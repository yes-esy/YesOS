# 1. 创建两个小程序

如何实现多进程？让我们先以两个简单的程序为例：

```c
void first_task_entry(void)
{
    int count = 0;
    for (;;)
    {
        log_printf("first_task_entry , count is %d", count++);
    }
}
void init_main()
{
    log_printf("Kernel is running . . .");
    log_printf("Version:%s", OS_VERSION);
    int count = 0;
    for (;;)
    {
        log_printf("init main , count is %d", count++);
    }
}
```

​	上述两段代码并不能实现交替的(并发)执行，而是当`OS`内核初始化完成后，执行`init_main()`然后一直执行`log_printf("init main , count is %d", count++);`。并不能跳转到`first_task_entry中执行`。

​	那么该如何实现切换使其交替执行呢？让我们逐步实现。

# 2.添加任务段

​	为了能让多个程序同时得到执行，`OS`会轮流在不同的程序间给予一定的时间运行。当然从一个程序切换至另一个程序时，会先将之前的程序运行状态保存起来，然后切换。等到将来再恢复到该程序运行时，恢复到之前运行状态，继续往下运行。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/12764787/1654241182056-4eee8371-1c22-4e49-955f-9f27536c756d.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_13%2Ctext_5p2O6L-w6ZOc%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp)

​	`x86`在硬件上对这种运行状态的保存和恢复提供了相应的支持，即通过`TSS`（任务状态段）保存有关任务的运行状态。

![image-20250424191649429](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424191649429.png)

​	相关定义如下：

```c
/**
 * task-state segment
 * 任务状态段结构(TSS)
 */
typedef struct _tss_t
{
    uint32_t pre_link;                               // 前一任务链接
    uint32_t esp0, ss0, esp1, ss1, esp2, ss2;        // 栈相关 不同特权级的栈
    uint32_t cr3;                                    // 页表
    uint32_t eip, eflags;                            // 运行状态
    uint32_t eax, ecx, edx, ebx, esp, ebp, esi, edi; // 通用寄存器
    uint32_t es, cs, ss, ds, fs, gs;                 // 段寄存器
    uint32_t ldt;                                    // ldt相关
    uint32_t iomap;                                  //
} tss_t;		
```

# 3.任务的简单初始化

​	`OS`在多个程序间切换运行的方法：<span style='color:red'>保存前一程序运行状态到TSS中，再从下一程序的TSS中提取运行状态恢复到相应的位置。</span>反复地保存-恢复-保存-...-恢复，就能实现一颗`CPU`内核，能够在多个程序间执行相应地代码，从而使得每个程序看起来实在独占`CPU`运行。

![image-20250424192833122](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424192833122.png)

TSS结构可以大致分为如下及部分，我们重点关注前4部分即可，后续将详细了解`CR3`.

![image-20250424192906046](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424192906046.png)

​	通过TSS结构，我们就能够知道一个程序当前地运行状态。==在进行不同程序运行地切换时，需要将前一个程序完整地运行状态保存到TSS，这样当后续该程序需要再次运行时，再将该状态进行从TSS中恢复==，从而就像能完整地继续从上次切换地位置继续往下运行，好像什么都没发生一样。

​	具体而言，一个程序运行起来后，首先会为程序代码（.text）、使用到的数据（.data .bss 全局变量 局部变量等）分配存储空间，即如我们在loader将kernel加载到内存中运行时，需要将相应地代码和数据从文件中拷贝到特定地内存位置。这些内存区域将会在程序运行起来后被程序独自占有，不会被其他程序地运行所修改，所以这些内存中地当前内容虽然体现了当前程序地执行状态，但是并不需要保存。(**==程序的代码和数据段在内存中已经有固定位置，它们不会被其他程序覆盖或修改,所以并不需要保存==**。)

​	而程序运行时在访问程序的代码和数据段所在的内存空间时，需要使用到`CS/SS/ES/DS/FS/GS`这些段寄存器，而这些寄存器在`CPU`中只有一份，是被多个程序所共享的。所以，为了在程序恢复运行时，这些段寄存器要和之前相同，TSS中要有相应的字段，来保存该程序使用了哪些段。

![image-20250424194957754](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424194957754.png)

​	此外，程序在运行时，还会使用到各种通用寄存器进行运算、数据访问，因此这些寄存器也体现了当前程序的运行状态，因此也需要保存起来。

​	`EFLAGS`寄存器中有相应的标志位，其中的值受之前执行指令的影响，同时后面的条件跳转指令会依赖这些标志，因此也需要保存；否则，当程序恢复运行时，这些标志位没有恢复为原来的值，将导致接下来的跳转指令跳转到错误的位置。

​	`EIP`寄存器指定了当前执行的指令地址，显然这个值需要在切换之前保存起来，以便于当程序恢复运行时，继续从之前的位置往下运行。

​	综上所述，目前只需要在切换时保存好当前的`段寄存器、通用寄存器、EIP、EFLAGS`中的内容到当前程序的`TSS`中，然后再加载下一个将要运行程序的`TSS`中`段寄存器、通用寄存器、EIP、EFLAGS值`进行恢复。

```c
/**
 * @brief        :
 * @param         {task_t *} task: 需要运行的任务
 * @param         {uint32_t} entry: 入口地址
 * @param         {uint32_t} esp: 栈顶指针
 * @return        {int} 成功为0 ,失败为-1
 **/
static int tss_init(task_t *task, uint32_t entry, uint32_t esp)
{
  

    kernel_memset(&task->tss, 0, sizeof(tss_t)); // 清零 , 第一次运行无关紧要
    task->tss.eip = entry;                       // 当前任务没有运行过,所以eip为当前任务的入口地址
    task->tss.esp = task->tss.esp0 = esp;        // esp0特权级0 , 设置栈地址

    // 平坦模型只有两个段cs和ds 其中ss , es , ds , fs , gs 设置为ds
    task->tss.ss = task->tss.ss0 = KERNEL_SELECTOR_DS;
    task->tss.es = task->tss.ds = task->tss.fs = task->tss.gs = KERNEL_SELECTOR_DS;

    // 设置cs
    task->tss.cs = KERNEL_SELECTOR_CS;
    task->tss.iomap = 0;
    // eflags
    task->tss.eflags = EFLAGS_DEFAULT | EFLAGS_IF;
    return 0;
}

/**
 * @brief        : 实现从一个任务到另一个任务的切换
 * @param         {task_t *} from: 当前任务
 * @param         {task_t *} to: 切换到的任务
 * @return        {*}
 **/
int task_init (task_t *task, uint32_t entry, uint32_t esp) {
    ASSERT(task != (task_t *)0);

    tss_init(task, entry, esp);
    return 0;
}

```

# 4.简单双任务相互切换

​	在为任务配置好`TSS`之后，还需要将其加入到`CPU`的硬件数据配置中，添加方法是在`GDT`表中添加一个专门的`TSS`描述符指向该结构，如下图所示。然后，当前执行哪个任务，则由`Task Register`指向相应的描述符。

![image-20250424200327586](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424200327586.png)

​	在系统初始化时，必须向`Task Register`写入一个有效的TSS描述符对应的选择子。在我们的实现中，写入的则是init_main()对应的描述选择子，即其为最开始运行的任务。

>  `Task Register (TR)`
>
> `Task Register`是x86架构中的一个特殊寄存器，用于指向当前正在执行的任务的TSS。它由两部分组成:
>
> - **可见部分**: 一个16位的选择子(Selector)，用于在GDT中查找当前任务的TSS描述符
> - **不可见部分**: 包含TSS描述符的基地址、界限和属性的缓存

​	`TSS`描述符的内容与代码段、数据段描述符等结构类似，主要区别在于`Type`字段。在任务初始化时，从`GDT`表中分配了相应的空闲描述符，然后按`TSS`描述符格式进行初始化。

![image-20250424202841681](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424202841681.png)

​	配置完所有的描述符之后，就可以通过远跳转`far_jump()`跳转到另一个任务运行。在执行该指令时，`CPU`会自动将保存当前任务的状态到`TSS`，然后从另一任务的`TSS`中取出状态进行恢复。通过不断地反复跳转，实现了在不同任务之间轮流切换执行。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/12764787/1654300895175-b377ba19-8449-4c6b-adbb-83143d631df2.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_17%2Ctext_5p2O6L-w6ZOc%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp)

```c
/**
 * @brief        : 切换至TSS,即跳转实现任务切换
 * @param         {uint16_t} tss_selector: 对应的tss选择子
 * @return        {*}
**/
void switch_to_tss(uint32_t tss_selector)
{
    far_jump(tss_selector, 0);
}	
```

大致流程：

1. 操作系统为任务创建TSS结构，填充初始状态
2. 在GDT中创建对应的TSS描述符，指向这个TSS
3. 执行LTR指令，将TSS描述符的选择子加载到TR寄存器
4. CPU使用TR中的选择子在GDT中查找TSS描述符
5. 从TSS描述符中获取TSS的基地址和界限
6. 根据这些信息访问TSS，获取或保存任务状态

![image-20250424204556024](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424204556024.png)

大致实现：

```c
/*code/source/kernel/init/init.c*/
static task_t init_task;  // 初始任务
static task_t first_task; // 第一个任务
static uint32_t first_task_stack[1024];
void first_task_entry(void)
{
    int count = 0;
    for (;;)
    {
        log_printf("first_task_entry , count is %d", count++);
        task_switch_from_to(&first_task, &init_task);
    }
}

void init_main()
{
    // int a = 3 / 0;
    //  irq_enable_global(); // 测试打开全局中断
    log_printf("Kernel is running . . .");
    log_printf("Version:%s", OS_VERSION);
    task_init(&first_task, (uint32_t)first_task_entry, (uint32_t)&first_task_stack[1024]); // x86栈地址由高到低增长 ,同时init_task需要一个单独的栈空间。
    task_init(&init_task, 0, 0);
    write_tr(init_task.tss_sel);
    int count = 0;
    for (;;)
    {
        log_printf("init main , count is %d", count++);
        task_switch_from_to(&init_task, &first_task);
    }
}
```

```c
/**
 * @brief        : 对指定任务的TSS进行初始化包括设置GDT表项,寄存器设置,任务入口地址
 * @param         {task_t *} task: 需要运行的任务
 * @param         {uint32_t} entry: 入口地址
 * @param         {uint32_t} esp: 栈顶指针
 * @return        {int} 成功为0 ,失败为-1
 * @file 		 :code/source/kernel/core/task.c
 **/
static int tss_init(task_t *task, uint32_t entry, uint32_t esp)
{
    int tss_sel = gdt_alloc_desc(); // 分配一个空闲表项
    if (tss_sel < 0)
    {
        log_printf("alloc tss failed!!!\n");
        return -1;
    }
    segment_desc_set(tss_sel, (uint32_t)&task->tss, sizeof(tss_t),
                     SEG_P_PRESENT | SEG_DPL0 | SEG_TYPE_TSS);

    kernel_memset(&task->tss, 0, sizeof(tss_t)); // 清零 , 第一次运行无关紧要
    task->tss.eip = entry;                       // 当前任务没有运行过,所以eip为当前任务的入口地址
    task->tss.esp = task->tss.esp0 = esp;        // esp0特权级0 , 设置栈地址

    // 平坦模型只有两个段cs和ds 其中ss , es , ds , fs , gs 设置为ds
    task->tss.ss = task->tss.ss0 = KERNEL_SELECTOR_DS;
    task->tss.es = task->tss.ds = task->tss.fs = task->tss.gs = KERNEL_SELECTOR_DS;

    // 设置cs
    task->tss.cs = KERNEL_SELECTOR_CS;
    task->tss.iomap = 0;
    // eflags
    task->tss.eflags = EFLAGS_DEFAULT | EFLAGS_IF;
    task->tss_sel = tss_sel;
    return 0;
}

/**
 * @brief        : 分配一个空闲gdt表项
 * @return        {int} 选择子
 * @file 		 :  code/source/kernel/cpu/cpu.c
 **/
int gdt_alloc_desc(void)
{
    // 跳过第0项
    for (int i = 1; i < GDT_TABLE_SIZE; i++)
    {
        segment_desc_t *desc = gdt_table + i;
        if (desc->attr == 0) // 该表项为空闲
        {
            return i * sizeof(segment_desc_t);
        }
    }
    return -1;
}

```



# 5.更简单高效的任务切换方法

​	计算机硬件上已经为这种切换机制提供了支持，就是通过任务状态段。一个任务或进程，它所有的运行状态在进行任务切换之前都会保存到这个任务状态段之中。然后当任务需要恢复运行的时候，就会从这个任务状态段中提取出相应的寄存器的值，恢复到`CPU`内部的内核寄存器中。

![image-20250424210052085](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424210052085.png)

​	这种机制看起来比较简单，但实际上效率是比较低的。因为在切换过程中，硬件会做很多检查，比如说权限方面的检查，访问地址范围方面的检查等等。整个过程比较耗时，所以操作系统一般不会采用这种切换方式。

​	在前面我们分析了有哪些寄存器需要保存，哪一些不需要。比如我们根据函数的调用原理分析出其中一些寄存器不需要保存。以及我们后面考虑到，所有任务都会使用相同的段寄存器，所以一些段寄存器也不需要保存。

![image-20250424210334306](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424210334306.png)

​	在保存这些任务状态的时候，我们分析了有哪些地方可以保存，其中最简单的方式就是保存在当前任务的栈中。选用任务栈进行保存，我们就可以简单的使用一些`PUSH`机令，就可以完成这些计算器的保存。

![image-20250424210808396](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20250424210808396.png)

​	所以最终任务切换这个过程就变成了将一些寄存器保存在当前任务的栈中，并且从下一个任务的栈中提取出相应寄存器值再恢复到 `CPU`的内核寄存器中。这个过程就是更加简单高效的进程上下文切换的过程。

```assembly
    # simple_switch(&from,&to)
simple_switch:
    mov 4(%esp),%eax  # 取from->stack 
    mov 8(%esp),%edx  # 取to->stack

    # 压栈,保存当前任务的状态
    push %ebp
    push %ebx
    push %esi
    push %edi

    # 切换当前栈
    mov %esp,(%eax)  # from->stack = esp
    mov %edx , %esp  # esp = to->stack
    
    # 加载下一任务的栈
    pop %edi
    pop %esi
    pop %ebx
    pop %ebp

    ret
```

